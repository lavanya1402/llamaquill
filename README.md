# ğŸ¦™ LlamaQuill â€” Local Blog Generator (Ollama + LangChain)

**LlamaQuill** lets you create thoughtful, audience-tuned blogs entirely on your own computer using **local Ollama models**.
No API keys, no cloud dependencies â€” your system becomes the writerâ€™s studio.

---

### âœ¨ Features

* Runs completely **offline** with local Ollama models such as *LLaMA 3*, *Mistral*, *Phi 3*, and *Qwen 2.5*
* Generates full blogs based on your topic, word count, and target audience
* Adjustable creativity controls for tone and length
* Optional **Streamlit interface** for an intuitive, interactive experience

---

### ğŸ§  How It Works

LlamaQuill combines **LangChainâ€™s ChatOllama** with the **Ollama runtime** running locally.
You provide a topic and target audience; the model crafts a coherent, structured blog post with headings and a concise conclusion.
Everything executes securely on your machine â€” no internet connection required.

---

### ğŸ§± Technology

* **Ollama** â€“ Local LLM runtime for model inference
* **LangChain Community** â€“ ChatOllama wrapper for prompt handling
* **Streamlit** *(optional)* â€“ Web-based UI for quick experimentation
* **Python 3.9 +** â€“ Core environment

---

### ğŸ§© Project Highlights

* Lightweight, privacy-friendly AI writing assistant
* Ideal for bloggers, educators, and researchers exploring local LLMs
* Simple structure that can be extended to any creative-writing task

---

### ğŸ’™ Author

Developed with â¤ï¸ by **[Lavanya Srivastava](https://www.linkedin.com/in/lavanya-srivastava/)**
Powered by *LangChain + Ollama (local models)* â€” with an optional Streamlit touch for interactivity.

